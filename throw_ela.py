from elasticsearch import Elasticsearch, helpers
import mysql.connector
import urllib3
from datetime import datetime
import pycountry
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderTimedOut
import re
import traceback

# ğŸ”§ SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings()

# âœ… Elasticsearch ì„¤ì •
es = Elasticsearch(
    hosts=["http://localhost:9200"],
    basic_auth=("elastic", "1234"),
    verify_certs=False
)

posts_index = "darkweb_posts_with_geo"
emails_index = "darkweb_email_domains"

# âœ… ì¸ë±ìŠ¤ ì‚­ì œ í•¨ìˆ˜
def delete_index(index_name):
    if es.indices.exists(index=index_name):
        es.indices.delete(index=index_name)
        print(f"ğŸ—‘ï¸ ì¸ë±ìŠ¤ '{index_name}' ì‚­ì œ ì™„ë£Œ")
    else:
        print(f"â„¹ï¸ ì¸ë±ìŠ¤ '{index_name}' ì—†ìŒ")

delete_index(posts_index)
delete_index(emails_index)

# âœ… ì¸ë±ìŠ¤ ìƒì„±
es.indices.create(index=posts_index, body={
    "mappings": {
        "properties": {
            "title": {"type": "text"},
            "author": {"type": "keyword"},
            "post_date": {"type": "date"},
            "keywords": {
                "type": "text",
                "fields": {"keyword": {"type": "keyword", "ignore_above": 256}}
            },
            "raw_body": {"type": "text"},
            "created_at": {"type": "date"},
            "country": {"type": "keyword"},
            "location": {"type": "geo_point"}
        }
    }
})
print(f"ğŸ“ ì¸ë±ìŠ¤ '{posts_index}' ìƒì„± ì™„ë£Œ")

es.indices.create(index=emails_index, body={
    "mappings": {
        "properties": {
            "email": {"type": "keyword"},
            "domain": {"type": "keyword"}
        }
    }
})
print(f"ğŸ“ ì¸ë±ìŠ¤ '{emails_index}' ìƒì„± ì™„ë£Œ")

# âœ… MariaDB ì—°ê²°
config = {
    "host": "localhost",
    "user": "root",
    "password": "1234",
    "database": "bcw",
    "port": 3306
}

try:
    conn = mysql.connector.connect(**config)
    cur = conn.cursor(dictionary=True)
    print("âœ… MariaDB ì—°ê²° ì„±ê³µ")
except Exception as e:
    print("âŒ MariaDB ì—°ê²° ì‹¤íŒ¨:", e)
    exit(1)

# âœ… ë„ì›€ë©” í•¨ìˆ˜ë“¤
def parse_datetime_field(dt):
    if isinstance(dt, datetime):
        return dt.isoformat()
    try:
        return datetime.strptime(dt, "%a %b %d, %Y %I:%M %p").isoformat()
    except:
        return None

country_names = set(c.name for c in pycountry.countries)
geolocator = Nominatim(user_agent="geo-extractor")
coordinates_cache = {}

def extract_country(text):
    if not text:
        return None
    for country in country_names:
        if re.search(rf"\\b{re.escape(country)}\\b", text, re.IGNORECASE):
            return country
    return None

def get_coordinates(country):
    if country in coordinates_cache:
        return coordinates_cache[country]
    try:
        location = geolocator.geocode(country, language="en", timeout=10)
        if location:
            coordinates_cache[country] = {"lat": location.latitude, "lon": location.longitude}
            return coordinates_cache[country]
    except GeocoderTimedOut:
        return None
    except Exception:
        return None
    return None

def extract_domain(email):
    if email and isinstance(email, str):
        match = re.search(r"@([\w.-]+)$", email)
        return match.group(1).lower() if match else None
    return None

# âœ… ê²Œì‹œê³¸ ìƒì„±
posts_actions = []
try:
    cur.execute("SELECT * FROM parsed_posts")
    for row in cur.fetchall():
        created_at = parse_datetime_field(row.get("created_at"))
        post_date = parse_datetime_field(row.get("post_date"))
        raw_body = row.get("raw_body") or ""
        country = extract_country(raw_body)
        location = get_coordinates(country) if country else None

        doc = {
            "title": row.get("title", ""),
            "author": row.get("author", ""),
            "post_date": post_date,
            "keywords": row.get("keywords", ""),
            "raw_body": raw_body,
            "created_at": created_at,
            "country": country or "",
            "location": location
        }

        posts_actions.append({
            "_index": posts_index,
            "_id": row["id"],
            "_source": doc
        })
    helpers.bulk(es, posts_actions)
    print(f"âœ… ê²Œì‹œë¬¼ {len(posts_actions)}ê°œ ìƒì„± ì™„ë£Œ")
except Exception as e:
    print("âŒ ê²Œì‹œë¬¼ ìƒì„± ì˜¤ë¥˜:", e)
    traceback.print_exc()

# âœ… ì´ë©”ì¼ ìƒì„±
emails_actions = []
try:
    cur.execute("SELECT email FROM parsed_emails WHERE email IS NOT NULL AND email != ''")
    for row in cur.fetchall():
        email = row.get("email")
        domain = extract_domain(email)
        if domain:
            emails_actions.append({
                "_index": emails_index,
                "_id": email.lower(),
                "_source": {"email": email.lower(), "domain": domain}
            })
    helpers.bulk(es, emails_actions)
    print(f"âœ… ì´ë©”ì¼ {len(emails_actions)}ê°œ ìƒì„± ì™„ë£Œ")
except Exception as e:
    print("âŒ ì´ë©”ì¼ ìƒì„± ì˜¤ë¥˜:", e)
    traceback.print_exc()

cur.close()
conn.close()